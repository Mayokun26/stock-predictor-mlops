# Stock Market MLOps Predictor

A production-ready MLOps system for predicting stock prices using machine learning, news sentiment analysis, and automated deployment pipelines.

## ğŸš€ Quick Start

```bash
# 1. Setup the system
make setup

# 2. Run the complete pipeline
make run-pipeline

# 3. Start the API
make run-api

# 4. Test a prediction
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"symbol": "AAPL", "news_headlines": ["Apple reports strong earnings"]}'
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚â”€â”€â”€â”€â”‚  Data Pipeline  â”‚â”€â”€â”€â”€â”‚  Feature Store  â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Yahoo Finance â”‚    â”‚ â€¢ Data cleaning â”‚    â”‚ â€¢ SQLite DB     â”‚
â”‚ â€¢ News APIs     â”‚    â”‚ â€¢ Feature eng   â”‚    â”‚ â€¢ Price history â”‚
â”‚ â€¢ Market Data   â”‚    â”‚ â€¢ Validation    â”‚    â”‚ â€¢ Technical ind â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model Training  â”‚â”€â”€â”€â”€â”‚ Model Registry  â”‚â”€â”€â”€â”€â”‚ Model Serving   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ MLflow        â”‚    â”‚ â€¢ Version       â”‚    â”‚ â€¢ FastAPI       â”‚
â”‚ â€¢ Experiments   â”‚    â”‚   control       â”‚    â”‚ â€¢ Docker        â”‚
â”‚ â€¢ Validation    â”‚    â”‚ â€¢ Artifacts     â”‚    â”‚ â€¢ Health checks â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Monitoring    â”‚    â”‚   Deployment    â”‚    â”‚   Frontend      â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Prometheus    â”‚    â”‚ â€¢ Docker        â”‚    â”‚ â€¢ API docs      â”‚
â”‚ â€¢ Health checks â”‚    â”‚ â€¢ Kubernetes    â”‚    â”‚ â€¢ Swagger UI    â”‚
â”‚ â€¢ Alerting      â”‚    â”‚ â€¢ CI/CD ready   â”‚    â”‚ â€¢ Monitoring    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Installation

### Prerequisites
- Python 3.9+
- Docker (optional)
- Make (optional, for convenience commands)

### Local Setup
```bash
# Clone and setup
git clone <repo-url>
cd betting
make setup

# Or manual setup
pip install -r requirements.txt
python setup_database.py
```

### Docker Setup
```bash
# Build and run with Docker
make docker-build
make docker-run

# Services will be available at:
# API: http://localhost:8000
# MLflow: http://localhost:5000
```

## ğŸ”„ Usage

### 1. Data Collection
```bash
# Collect stock market data
make collect-data

# Or run directly
python collect_data.py
```

### 2. Model Training
```bash
# Train ML models with MLflow tracking
make train-models

# Or run directly
python train_with_mlflow.py
```

### 3. Complete Pipeline
```bash
# Run end-to-end pipeline
make run-pipeline

# This will:
# - Setup database
# - Collect fresh data
# - Train models
# - Validate results
```

### 4. API Server
```bash
# Start the prediction API
make run-api

# Test the API
curl http://localhost:8000/health
```

## ğŸ” API Endpoints

### Health Check
```bash
GET /health
```
Returns system health status including database and model status.

### Stock Prediction
```bash
POST /predict
Content-Type: application/json

{
  "symbol": "AAPL",
  "news_headlines": [
    "Apple reports strong quarterly earnings",
    "New iPhone sales exceed expectations"
  ]
}
```

Returns:
```json
{
  "symbol": "AAPL",
  "current_price": 150.25,
  "predicted_price": 152.80,
  "price_change": 2.55,
  "sentiment_score": 0.245,
  "confidence": 0.847,
  "timestamp": "2024-01-15T10:30:00"
}
```

### Available Stocks
```bash
GET /stocks
```
Returns list of available stocks for prediction.

## ğŸ“Š Monitoring

### Health Monitoring
```bash
# Run monitoring checks
make monitor

# Continuous monitoring
make monitor-live
```

### Metrics
- **API Performance**: Response times, error rates
- **Model Performance**: RMSE, RÂ² scores, confidence
- **Data Quality**: Freshness, completeness
- **System Health**: Database status, model availability

### Prometheus Metrics
Metrics are exposed at `http://localhost:8001/metrics` when monitoring is running.

## ğŸ§ª Testing

```bash
# Run all tests
make test

# Test API endpoints
make test-api

# Check system status
make status
```

## ğŸš€ Deployment

### Local Deployment
```bash
# Deploy locally with Docker
make deploy-local
```

### Production Deployment
```bash
# AWS deployment (requires setup)
make deploy-aws

# Or use Kubernetes manifests
kubectl apply -f k8s/
```

## ğŸ“ Project Structure

```
betting/
â”œâ”€â”€ api.py                 # FastAPI application
â”œâ”€â”€ pipeline.py           # MLOps pipeline orchestrator
â”œâ”€â”€ monitoring.py         # System monitoring
â”œâ”€â”€ collect_data.py       # Data collection
â”œâ”€â”€ train_with_mlflow.py  # Model training
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ Dockerfile           # Container definition
â”œâ”€â”€ docker-compose.yml   # Multi-service setup
â”œâ”€â”€ Makefile            # Automation commands
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/           # Data ingestion modules
â”‚   â”œâ”€â”€ database/       # Database models
â”‚   â”œâ”€â”€ models/         # ML models
â”‚   â””â”€â”€ api/           # API components
â”œâ”€â”€ tests/             # Test suite
â”œâ”€â”€ mlruns/           # MLflow experiments
â”œâ”€â”€ monitoring/       # Monitoring reports
â””â”€â”€ models/           # Trained model artifacts
```

## ğŸ”§ Configuration

### Environment Variables
```bash
# Data sources
ALPHA_VANTAGE_API_KEY=your_key
ALPACA_API_KEY=your_key
ALPACA_SECRET_KEY=your_secret

# MLflow
MLFLOW_TRACKING_URI=file:///app/mlruns

# API
API_HOST=0.0.0.0
API_PORT=8000
```

### Database Configuration
The system uses SQLite by default. For production, configure PostgreSQL:

```python
# src/config.py
DATABASE_URL = "postgresql://user:pass@localhost/mlops"
```

## ğŸ“ˆ MLflow Integration

### Experiment Tracking
- All model training is tracked in MLflow
- Experiments are organized by date and model type
- Metrics, parameters, and artifacts are logged automatically

### Model Registry
- Models are versioned and stored in MLflow
- Production models can be tagged for deployment
- Model lineage and performance history is tracked

### Access MLflow UI
```bash
# Start MLflow server
make run-mlflow

# Access at http://localhost:5000
```

## ğŸ¯ Features

### Core Functionality
- âœ… **Real-time Predictions**: REST API for stock price predictions
- âœ… **Sentiment Analysis**: News headline sentiment using FinBERT
- âœ… **Technical Analysis**: RSI, moving averages, volatility indicators
- âœ… **Multiple Models**: Random Forest, Linear Regression with comparison
- âœ… **Data Pipeline**: Automated data collection and processing

### MLOps Features
- âœ… **Experiment Tracking**: MLflow integration for all experiments
- âœ… **Model Versioning**: Automatic model versioning and storage
- âœ… **Containerization**: Docker containers for all components
- âœ… **Health Monitoring**: Comprehensive system health checks
- âœ… **API Documentation**: Auto-generated OpenAPI docs
- âœ… **Prometheus Metrics**: System and model performance metrics

### Production Ready
- âœ… **Scalable Architecture**: Microservices with Docker Compose
- âœ… **Error Handling**: Comprehensive error handling and logging
- âœ… **Data Validation**: Input validation and data quality checks
- âœ… **Security**: Non-root containers, input sanitization
- âœ… **Documentation**: Complete API and system documentation

## ğŸ“ Learning Outcomes

This project demonstrates key MLOps competencies:

1. **Data Engineering**: Automated data pipelines, quality checks
2. **Model Development**: Experiment tracking, model comparison
3. **Model Serving**: Production API deployment, monitoring
4. **DevOps Integration**: Containerization, CI/CD readiness
5. **Monitoring & Observability**: Health checks, metrics, alerting

## ğŸš¨ Troubleshooting

### Common Issues

**API not starting**
```bash
# Check if port is in use
lsof -i :8000

# Check logs
make docker-logs
```

**Database issues**
```bash
# Reinitialize database
rm stocks.db
python setup_database.py
```

**Model training fails**
```bash
# Check data availability
python -c "import sqlite3; conn=sqlite3.connect('stocks.db'); print(conn.execute('SELECT COUNT(*) FROM stock_prices').fetchone())"

# Collect fresh data
make collect-data
```

**Docker issues**
```bash
# Rebuild containers
make docker-stop
make docker-build
make docker-run
```

## ğŸ“ License

MIT License - see LICENSE file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests: `make test`
5. Submit a pull request

## ğŸ“ Support

For issues and questions:
- Check the troubleshooting section
- Review logs: `make docker-logs`
- Run health checks: `make monitor`
- Check system status: `make status`